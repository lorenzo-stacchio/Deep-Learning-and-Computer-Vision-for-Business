{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCMycQ_2U8SA"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/open-mmlab/mmdetection/raw/3.x/resources/mmdet-logo.png\" width=\"600\"/>\n",
        "  <div>&nbsp;</div>\n",
        "  <div align=\"center\">\n",
        "    <b><font size=\"5\">OpenMMLab website</font></b>\n",
        "    <sup>\n",
        "      <a href=\"https://openmmlab.com\">\n",
        "        <i><font size=\"4\">HOT</font></i>\n",
        "      </a>\n",
        "    </sup>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;\n",
        "    <b><font size=\"5\">OpenMMLab platform</font></b>\n",
        "    <sup>\n",
        "      <a href=\"https://platform.openmmlab.com\">\n",
        "        <i><font size=\"4\">TRY IT OUT</font></i>\n",
        "      </a>\n",
        "    </sup>\n",
        "  </div>\n",
        "  <div>&nbsp;</div>\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/open-mmlab/mmdetection/blob/dev-3.x/demo/MMDet_Tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "[![PyPI](https://img.shields.io/pypi/v/mmdet)](https://pypi.org/project/mmdet)\n",
        "[![docs](https://img.shields.io/badge/docs-latest-blue)](https://mmdetection.readthedocs.io/en/latest/)\n",
        "[![badge](https://github.com/open-mmlab/mmdetection/workflows/build/badge.svg)](https://github.com/open-mmlab/mmdetection/actions)\n",
        "[![codecov](https://codecov.io/gh/open-mmlab/mmdetection/branch/master/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmdetection)\n",
        "[![license](https://img.shields.io/github/license/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/blob/master/LICENSE)\n",
        "[![open issues](https://isitmaintained.com/badge/open/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/issues)\n",
        "[![issue resolution](https://isitmaintained.com/badge/resolution/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/issues)\n",
        "\n",
        "[üìòDocumentation](https://mmdetection.readthedocs.io/en/3.x/) |\n",
        "[üõ†Ô∏èInstallation](https://mmdetection.readthedocs.io/en/3.x/get_started.html) |\n",
        "[üëÄModel Zoo](https://mmdetection.readthedocs.io/en/3.x/model_zoo.html) |\n",
        "[üÜïUpdate News](https://mmdetection.readthedocs.io/en/3.x/notes/changelog.html) |\n",
        "[üöÄOngoing Projects](https://github.com/open-mmlab/mmdetection/projects) |\n",
        "[ü§îReporting Issues](https://github.com/open-mmlab/mmdetection/issues/new/choose)\n",
        "\n",
        "</div>\n",
        "\n",
        "<div align=\"center\">\n",
        "  <a href=\"https://openmmlab.medium.com/\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/219255827-67c1a27f-f8c5-46a9-811d-5e57448c61d1.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://discord.com/channels/1037617289144569886/1046608014234370059\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://twitter.com/OpenMMLab\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://www.youtube.com/openmmlab\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://space.bilibili.com/1293512903\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/219026751-d7d14cce-a7c9-4e82-9942-8375fca65b99.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://www.zhihu.com/people/openmmlab\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/219026120-ba71e48b-6e94-4bd4-b4e9-b7d175b5e362.png\" width=\"3%\" alt=\"\" /></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGYwt_UjIrqp"
      },
      "source": [
        "# Object Detection\n",
        "\n",
        "In this tutorial, you will learn:\n",
        "- the basic structure of RTMDet.\n",
        "- to perform inference with a MMDetection detector.\n",
        "- to train a new detector with a new dataset.\n",
        "\n",
        "Let's start!\n",
        "\n",
        "```{note}\n",
        "The commands in this tutorial are mainly for Colab.\n",
        "You can click the button above, `Open in Colab`, to run this notebook in Colab.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJxJHruNLb7Y"
      },
      "source": [
        "## Install MMDetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi4LPmsR66sy",
        "outputId": "ba8fb3b5-9f71-43bb-edbb-8f0f2736ccd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkGnB9WyHSXB",
        "outputId": "e2099f66-ce4c-4fab-9a2a-afcc973bb39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openmim in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim) (0.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (2.2.2)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.28.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.7)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (3.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.65.2)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\n",
            "Requirement already satisfied: filelock~=3.14.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (3.14.0)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
            "Requirement already satisfied: packaging~=24.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (24.1)\n",
            "Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.10/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.10/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (43.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.4.0/index.html\n",
            "Collecting mmengine>=0.7.0\n",
            "  Downloading mmengine-0.10.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting addict (from mmengine>=0.7.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (6.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (2.5.0)\n",
            "Collecting yapf (from mmengine>=0.7.0)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.7.0) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.7.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.7.0) (2.18.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (8.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine>=0.7.0) (2.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine>=0.7.0) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.7.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.7.0) (1.16.0)\n",
            "Downloading mmengine-0.10.5-py3-none-any.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m452.3/452.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, yapf, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.10.5 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.4.0/index.html\n",
            "Collecting mmcv>=2.0.0rc4\n",
            "  Using cached https://download.openmmlab.com/mmcv/dist/cu121/torch2.4.0/mmcv-2.2.0-cp310-cp310-manylinux1_x86_64.whl (98.7 MB)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (0.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (24.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (10.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc4) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (8.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc4) (2.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc4) (3.20.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.2.0\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 38023, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 38023 (delta 0), reused 1 (delta 0), pack-reused 38019 (from 1)\u001b[K\n",
            "Receiving objects: 100% (38023/38023), 63.18 MiB | 21.88 MiB/s, done.\n",
            "Resolving deltas: 100% (26236/26236), done.\n",
            "/content/mmdetection\n",
            "Obtaining file:///content/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.26.4)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (2.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.13.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (1.16.0)\n",
            "Collecting terminaltables (from mmdet==3.3.0)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet==3.3.0) (4.65.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet==3.3.0) (2.8.2)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-3.3.0 terminaltables-3.1.10\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "%pip install -U openmim\n",
        "!mim install \"mmengine>=0.7.0\"\n",
        "!mim install \"mmcv>=2.0.0rc4\"\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install \"mmcv>=2.0.0rc4,<2.2.0\" --no-binary :all:"
      ],
      "metadata": {
        "id": "kxnImeBFUsXB",
        "outputId": "33d3a11e-fbcb-413f-854a-ac6fee4d907a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mmcv<2.2.0,>=2.0.0rc4\n",
            "  Downloading mmcv-2.1.0.tar.gz (471 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/471.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m471.0/471.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m471.4/471.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (0.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (24.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (10.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4) (0.40.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (2.5.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (4.10.0.84)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4) (8.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4) (2.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.2.0,>=2.0.0rc4) (3.20.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv<2.2.0,>=2.0.0rc4) (1.16.0)\n",
            "Building wheels for collected packages: mmcv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YeUiqAoCaoV"
      },
      "outputs": [],
      "source": [
        "from mmengine.utils import get_git_hash\n",
        "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
        "\n",
        "import mmdet\n",
        "\n",
        "\n",
        "def collect_env():\n",
        "    \"\"\"Collect the information of the running environments.\"\"\"\n",
        "    env_info = collect_base_env()\n",
        "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
        "    return env_info\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for name, val in collect_env().items():\n",
        "        print(f'{name}: {val}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi9zw03oM4CH"
      },
      "source": [
        "## Perform Inference with An MMDet detector\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s99mDGBG1S1z"
      },
      "source": [
        "### An efficient Real-Time one-stage detector\n",
        "\n",
        "In this tutorial, we use RTMDet, an efficient Real-Time one-stage detector as an example.\n",
        "\n",
        "The high-level architecture of RTMDet is shown in the following picture. More details can be found in the [paper](https://arxiv.org/abs/2212.07784).\n",
        "\n",
        "![RTMDet](https://user-images.githubusercontent.com/27466624/225922103-404064c1-3cb0-4ab5-9388-79f9517dcdb0.jpg)\n",
        "\n",
        "To obtain a more efficient model architecture, MMDetection explore an architecture that has compatible capacities in the backbone and neck, constructed by a basic building block that consists of large-kernel depth-wise convolutions. MMDetection further introduce soft labels when calculating matching costs in the dynamic label assignment to improve accuracy. Together with better training techniques, the resulting object detector, named RTMDet, achieves 52.8% AP on COCO with 300+ FPS on an NVIDIA 3090 GPU, outperforming the current mainstream industrial detectors. RTMDet achieves the best parameter-accuracy trade-off with tiny/small/medium/large/extra-large model sizes for various application scenarios, and obtains new state-of-the-art performance on real-time instance segmentation and rotated object detection. We hope the experimental results can provide new insights into designing versatile real-time object detectors for many object recognition tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4doHX4exvS1"
      },
      "outputs": [],
      "source": [
        "# We download the pre-trained checkpoints for inference and finetuning.\n",
        "!mkdir ./checkpoints\n",
        "!mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest ./checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLgFRMtP91ue"
      },
      "source": [
        "### Inference the detector\n",
        "\n",
        "Since the model is successfully created and loaded, let's see how good it is. We use the high-level API `DetInferencer` implemented in the MMDetection. This API is created to ease the inference process. The details of the codes can be found [here](https://github.com/open-mmlab/mmdetection/blob/dev-3.x/mmdet/apis/det_inferencer.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi6DRpsQPEmV"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import DetInferencer\n",
        "\n",
        "# Choose to use a config\n",
        "model_name = 'rtmdet_tiny_8xb32-300e_coco'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = './checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
        "\n",
        "# Set the device to be used for evaluation\n",
        "device = 'cuda:0'\n",
        "\n",
        "# Initialize the DetInferencer\n",
        "inferencer = DetInferencer(model_name, checkpoint, device)\n",
        "\n",
        "# Use the detector to do inference\n",
        "img = './demo/demo.jpg'\n",
        "result = inferencer(img, out_dir='./output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6a8T4goU8Sq"
      },
      "outputs": [],
      "source": [
        "# Show the structure of result dict\n",
        "from rich.pretty import pprint\n",
        "pprint(result, max_length=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsJU5D-QPX8L"
      },
      "outputs": [],
      "source": [
        "# Show the output image\n",
        "from PIL import Image\n",
        "Image.open('./output/vis/demo.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GrWIJywLV-V"
      },
      "source": [
        "## Train with customized datasets\n",
        "\n",
        "In this part, you will know how to train predefined models with customized datasets and then test it. We use the [balloon dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon) as an example to describe the whole process.\n",
        "\n",
        "The basic steps are as below:\n",
        "\n",
        "1. Prepare the customized dataset\n",
        "2. Prepare a config\n",
        "3. Train, test, and infer models on the customized dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E73y5Lru-wBx"
      },
      "source": [
        "### Prepare the customized dataset\n",
        "\n",
        "There are three ways to support a new dataset in MMDetection:\n",
        "\n",
        "1. Reorganize the dataset into COCO format.\n",
        "2. Reorganize the dataset into a middle format.\n",
        "3. Implement a new dataset.\n",
        "\n",
        "Usually, we recommend using the first two methods which are usually easier than the third.\n",
        "\n",
        "In this tutorial, we use the ballon dataset an example of converting the data into COCO format.\n",
        "\n",
        "**Note**: Datasets and metrics have been decoupled except CityScapes since MMDetection 3.0. Therefore, users can use any kind of evaluation metrics for any format of datasets during validation. For example: evaluate on COCO dataset with VOC metric, or evaluate on OpenImages dataset with both VOC and COCO metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbJhEsckU8UX"
      },
      "outputs": [],
      "source": [
        "# Download the data and unzip it\n",
        "!python tools/misc/download_dataset.py --dataset-name balloon --save-dir data --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmMpkzs2U8UY"
      },
      "source": [
        "#### COCO annotation format\n",
        "The necessary keys of COCO format for instance segmentation are as below, for the complete details, please refer [here](https://cocodataset.org/#format-data).\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"images\": [image],\n",
        "    \"annotations\": [annotation],\n",
        "    \"categories\": [category]\n",
        "}\n",
        "image = {\n",
        "    \"id\": int,\n",
        "    \"width\": int,\n",
        "    \"height\": int,\n",
        "    \"file_name\": str,\n",
        "}\n",
        "annotation = {\n",
        "    \"id\": int,\n",
        "    \"image_id\": int,\n",
        "    \"category_id\": int,\n",
        "    \"segmentation\": RLE or [polygon],\n",
        "    \"area\": float,\n",
        "    \"bbox\": [x,y,width,height], # (x, y) are the coordinates of the upper left corner of the bbox\n",
        "    \"iscrowd\": 0 or 1,\n",
        "}\n",
        "categories = [{\n",
        "    \"id\": int,\n",
        "    \"name\": str,\n",
        "    \"supercategory\": str,\n",
        "}]\n",
        "```\n",
        "\n",
        "Assume we use the balloon dataset.\n",
        "After downloading the data, we need to implement a function to convert the annotation format into the COCO format. Then we can use implemented `CocoDataset` to load the data and perform training and evaluation.\n",
        "\n",
        "If you take a look at the dataset, you will find the dataset format is as below:\n",
        "\n",
        "```json\n",
        "{'base64_img_data': '',\n",
        " 'file_attributes': {},\n",
        " 'filename': '34020010494_e5cb88e1c4_k.jpg',\n",
        " 'fileref': '',\n",
        " 'regions': {'0': {'region_attributes': {},\n",
        "   'shape_attributes': {'all_points_x': [1020,\n",
        "     1000,\n",
        "     994,\n",
        "     1003,\n",
        "     1023,\n",
        "     1050,\n",
        "     1089,\n",
        "     1134,\n",
        "     1190,\n",
        "     1265,\n",
        "     1321,\n",
        "     1361,\n",
        "     1403,\n",
        "     1428,\n",
        "     1442,\n",
        "     1445,\n",
        "     1441,\n",
        "     1427,\n",
        "     1400,\n",
        "     1361,\n",
        "     1316,\n",
        "     1269,\n",
        "     1228,\n",
        "     1198,\n",
        "     1207,\n",
        "     1210,\n",
        "     1190,\n",
        "     1177,\n",
        "     1172,\n",
        "     1174,\n",
        "     1170,\n",
        "     1153,\n",
        "     1127,\n",
        "     1104,\n",
        "     1061,\n",
        "     1032,\n",
        "     1020],\n",
        "    'all_points_y': [963,\n",
        "     899,\n",
        "     841,\n",
        "     787,\n",
        "     738,\n",
        "     700,\n",
        "     663,\n",
        "     638,\n",
        "     621,\n",
        "     619,\n",
        "     643,\n",
        "     672,\n",
        "     720,\n",
        "     765,\n",
        "     800,\n",
        "     860,\n",
        "     896,\n",
        "     942,\n",
        "     990,\n",
        "     1035,\n",
        "     1079,\n",
        "     1112,\n",
        "     1129,\n",
        "     1134,\n",
        "     1144,\n",
        "     1153,\n",
        "     1166,\n",
        "     1166,\n",
        "     1150,\n",
        "     1136,\n",
        "     1129,\n",
        "     1122,\n",
        "     1112,\n",
        "     1084,\n",
        "     1037,\n",
        "     989,\n",
        "     963],\n",
        "    'name': 'polygon'}}},\n",
        " 'size': 1115004}\n",
        "```\n",
        "\n",
        "The annotation is a JSON file where each key indicates an image's all annotations.\n",
        "The code to convert the balloon dataset into coco format is as below.\n",
        "\n",
        "Using the function below, users can successfully convert the annotation file into json format, then we can use `CocoDataset` to train and evaluate the model with `CocoMetric`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHnw5Q_nARXq"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import mmcv\n",
        "from mmengine.fileio import dump, load\n",
        "from mmengine.utils import track_iter_progress\n",
        "\n",
        "def convert_balloon_to_coco(ann_file, out_file, image_prefix):\n",
        "    data_infos = load(ann_file)\n",
        "\n",
        "    annotations = []\n",
        "    images = []\n",
        "    obj_count = 0\n",
        "    for idx, v in enumerate(track_iter_progress(data_infos.values())):\n",
        "        filename = v['filename']\n",
        "        img_path = osp.join(image_prefix, filename)\n",
        "        height, width = mmcv.imread(img_path).shape[:2]\n",
        "\n",
        "        images.append(\n",
        "            dict(id=idx, file_name=filename, height=height, width=width))\n",
        "\n",
        "        for _, obj in v['regions'].items():\n",
        "            assert not obj['region_attributes']\n",
        "            obj = obj['shape_attributes']\n",
        "            px = obj['all_points_x']\n",
        "            py = obj['all_points_y']\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            x_min, y_min, x_max, y_max = (min(px), min(py), max(px), max(py))\n",
        "\n",
        "            data_anno = dict(\n",
        "                image_id=idx,\n",
        "                id=obj_count,\n",
        "                category_id=0,\n",
        "                bbox=[x_min, y_min, x_max - x_min, y_max - y_min],\n",
        "                area=(x_max - x_min) * (y_max - y_min),\n",
        "                segmentation=[poly],\n",
        "                iscrowd=0)\n",
        "            annotations.append(data_anno)\n",
        "            obj_count += 1\n",
        "\n",
        "    coco_format_json = dict(\n",
        "        images=images,\n",
        "        annotations=annotations,\n",
        "        categories=[{\n",
        "            'id': 0,\n",
        "            'name': 'balloon'\n",
        "        }])\n",
        "    dump(coco_format_json, out_file)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    convert_balloon_to_coco(ann_file='data/balloon/train/via_region_data.json',\n",
        "                            out_file='data/balloon/train.json',\n",
        "                            image_prefix='data/balloon/train')\n",
        "    convert_balloon_to_coco(ann_file='data/balloon/val/via_region_data.json',\n",
        "                            out_file='data/balloon/val.json',\n",
        "                            image_prefix='data/balloon/val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc9UDp1vU8UZ"
      },
      "source": [
        "## Prepare a config\n",
        "\n",
        "The second step is to prepare a config thus the dataset could be successfully loaded. Assume that we want to use RTMDet-tiny, the config to train the detector on balloon dataset is as below. Assume the config is under directory `configs/rtmdet/` and named as `rtmdet_tiny_1xb4-20e_balloon.py`, the config is as below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjTW6XydU8Ua"
      },
      "outputs": [],
      "source": [
        "config_balloon = \"\"\"\n",
        "# Inherit and overwrite part of the config based on this config\n",
        "_base_ = './rtmdet_tiny_8xb32-300e_coco.py'\n",
        "\n",
        "data_root = 'data/balloon/' # dataset root\n",
        "\n",
        "train_batch_size_per_gpu = 4\n",
        "train_num_workers = 2\n",
        "\n",
        "max_epochs = 20\n",
        "stage2_num_epochs = 1\n",
        "base_lr = 0.00008\n",
        "\n",
        "\n",
        "metainfo = {\n",
        "    'classes': ('balloon', ),\n",
        "    'palette': [\n",
        "        (220, 20, 60),\n",
        "    ]\n",
        "}\n",
        "\n",
        "train_dataloader = dict(\n",
        "    batch_size=train_batch_size_per_gpu,\n",
        "    num_workers=train_num_workers,\n",
        "    dataset=dict(\n",
        "        data_root=data_root,\n",
        "        metainfo=metainfo,\n",
        "        data_prefix=dict(img='train/'),\n",
        "        ann_file='train.json'))\n",
        "\n",
        "val_dataloader = dict(\n",
        "    dataset=dict(\n",
        "        data_root=data_root,\n",
        "        metainfo=metainfo,\n",
        "        data_prefix=dict(img='val/'),\n",
        "        ann_file='val.json'))\n",
        "\n",
        "test_dataloader = val_dataloader\n",
        "\n",
        "val_evaluator = dict(ann_file=data_root + 'val.json')\n",
        "\n",
        "test_evaluator = val_evaluator\n",
        "\n",
        "model = dict(bbox_head=dict(num_classes=1))\n",
        "\n",
        "# learning rate\n",
        "param_scheduler = [\n",
        "    dict(\n",
        "        type='LinearLR',\n",
        "        start_factor=1.0e-5,\n",
        "        by_epoch=False,\n",
        "        begin=0,\n",
        "        end=10),\n",
        "    dict(\n",
        "        # use cosine lr from 10 to 20 epoch\n",
        "        type='CosineAnnealingLR',\n",
        "        eta_min=base_lr * 0.05,\n",
        "        begin=max_epochs // 2,\n",
        "        end=max_epochs,\n",
        "        T_max=max_epochs // 2,\n",
        "        by_epoch=True,\n",
        "        convert_to_iter_based=True),\n",
        "]\n",
        "\n",
        "train_pipeline_stage2 = [\n",
        "    dict(type='LoadImageFromFile', backend_args=None),\n",
        "    dict(type='LoadAnnotations', with_bbox=True),\n",
        "    dict(\n",
        "        type='RandomResize',\n",
        "        scale=(640, 640),\n",
        "        ratio_range=(0.1, 2.0),\n",
        "        keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=(640, 640)),\n",
        "    dict(type='YOLOXHSVRandomAug'),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),\n",
        "    dict(type='PackDetInputs')\n",
        "]\n",
        "\n",
        "# optimizer\n",
        "optim_wrapper = dict(\n",
        "    _delete_=True,\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=base_lr, weight_decay=0.05),\n",
        "    paramwise_cfg=dict(\n",
        "        norm_decay_mult=0, bias_decay_mult=0, bypass_duplicate=True))\n",
        "\n",
        "default_hooks = dict(\n",
        "    checkpoint=dict(\n",
        "        interval=5,\n",
        "        max_keep_ckpts=2,  # only keep latest 2 checkpoints\n",
        "        save_best='auto'\n",
        "    ),\n",
        "    logger=dict(type='LoggerHook', interval=5))\n",
        "\n",
        "custom_hooks = [\n",
        "    dict(\n",
        "        type='PipelineSwitchHook',\n",
        "        switch_epoch=max_epochs - stage2_num_epochs,\n",
        "        switch_pipeline=train_pipeline_stage2)\n",
        "]\n",
        "\n",
        "# load COCO pre-trained weight\n",
        "load_from = './checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
        "\n",
        "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=max_epochs, val_interval=1)\n",
        "visualizer = dict(vis_backends=[dict(type='LocalVisBackend'),dict(type='TensorboardVisBackend')])\n",
        "\"\"\"\n",
        "\n",
        "with open('./configs/rtmdet/rtmdet_tiny_1xb4-20e_balloon.py', 'w') as f:\n",
        "    f.write(config_balloon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LNm7LxwZG2w"
      },
      "outputs": [],
      "source": [
        "!python tools/train.py configs/rtmdet/rtmdet_tiny_1xb4-20e_balloon.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vYQF5K2NqqI"
      },
      "source": [
        "### Understand the log\n",
        "From the log, we can have a basic understanding on the training process and know how well the detector is trained.\n",
        "\n",
        "First, since the dataset we are using is small, we loaded a pre-trained Faster R-CNN model and fine-tune it for detection.\n",
        "The original Faster R-CNN is trained on COCO dataset that contains 80 classes but KITTI Tiny dataset only have 3 classes. Therefore, the last FC layers of the pre-trained Faster R-CNN for classification and regression have different weight shape and are not used.\n",
        "\n",
        "Second, after training, the detector is evaluated by the default VOC-style evaluation. The results show that the detector achieves 58.1 mAP on the val dataset, not bad!\n",
        "\n",
        "We can also check the tensorboard to see the curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wpQGXu9aONh"
      },
      "outputs": [],
      "source": [
        "# load tensorboard in colab\n",
        "%load_ext tensorboard\n",
        "\n",
        "# see curves in tensorboard\n",
        "%tensorboard --logdir ./work_dirs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQ-yspZLuuI"
      },
      "source": [
        "From the tensorboard, we can observe that changes of loss and learning rate. We can see the losses of each branch gradually decrease as the training goes by.\n",
        "\n",
        "## Test the Trained Detector\n",
        "\n",
        "After finetuning the detector, let's visualize the prediction results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHDYQSRNNDxt"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import DetInferencer\n",
        "import glob\n",
        "\n",
        "# Choose to use a config\n",
        "config = 'configs/rtmdet/rtmdet_tiny_1xb4-20e_balloon.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = glob.glob('./work_dirs/rtmdet_tiny_1xb4-20e_balloon/best_coco*.pth')[0]\n",
        "\n",
        "# Set the device to be used for evaluation\n",
        "device = 'cuda:0'\n",
        "\n",
        "# Initialize the DetInferencer\n",
        "inferencer = DetInferencer(config, checkpoint, device)\n",
        "\n",
        "# Use the detector to do inference\n",
        "img = './data/balloon/val/4838031651_3e7b5ea5c7_b.jpg'\n",
        "result = inferencer(img, out_dir='./output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDzwbUsfN4lR"
      },
      "outputs": [],
      "source": [
        "# Show the output image\n",
        "Image.open('./output/vis/4838031651_3e7b5ea5c7_b.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1L8o3rtc37M"
      },
      "source": [
        "## What to Do Next?\n",
        "\n",
        "So far, we have learnt how to test and train a one-stage detector using MMDetection. To further explore MMDetection, you could do several other things as shown below:\n",
        "\n",
        "- Try YOLO series object detection using [MMYOLO](https://github.com/open-mmlab/mmyolo), also one of the OpenMMLab projects. In MMYOLO, not only can you try all the methods supported in MMDetection but also some YOLO series detectors.\n",
        "- Try rotated object detection using [MMRotate](https://github.com/open-mmlab/mmrotate), also one of the OpenMMLab projects. In MMRotate, not only can you try all the methods supported in MMDetection but also some rotated object detectors.\n",
        "- Try 3D object detection using [MMDetection3D](https://github.com/open-mmlab/mmdetection3d), also one of the OpenMMLab projects. In MMDetection3D, not only can you try all the methods supported in MMDetection but also some 3D object detectors.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}